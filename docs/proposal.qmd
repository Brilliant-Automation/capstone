---
title: "Intelligent Monitoring and Maintenance Prediction System for Industrial Equipment"
author: "Samuel Adetsi, Mu Ha, Cheng Zhang, Michael Hewlett"
format:
  pdf:
    toc: true
    toc-depth: 2
    number-sections: true
execute:
  echo: false
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

```{r}
#| label: setup
#| include: false

# Load required libraries
library(tidyverse)
library(knitr)
library(kableExtra)
```

\newpage

# Executive Summary

Brilliant Automation, a leader in industrial automation solutions in
Shanghai, China, has engaged our team to develop an intelligent
monitoring and predictive maintenance system for industrial equipments.
This project will leverage advanced data analytics and machine learning
to transform sensor data into actionable insights, supporting early
fault detection and optimized maintenance for key machinery.

# Introduction

Brilliant Automation specializes in advanced monitoring and control
systems for manufacturing and processing plants. To maximize equipment
reliability and operational efficiency, the company installs
high-frequency vibration and temperature sensors at critical points on
key machinery, such as motors, gearboxes and bearing housings, across
their clients' facilities. These sensors continuously collect data to
monitor the health of essential assets including Tube Mills, Belt
Conveyors, and High-Temperature Fans.

![](images/proposal_machinery_sensor.png) *Example of sensor placement
on industrial machinery*

This project aims to enhance their predictive maintenance capabilities.
By leveraging advanced data processing and machine learning, our system
will enable early detection of equipment issues, reduce unplanned
downtime, and optimize maintenance schedules. The focus of our analysis
will be on three key pieces of industrial machinery: a Tube Mill, Belt
Conveyor, and High-Temperature Fan. Our solution will integrate sensor
exploratory data analysis, machine learning predictions, and an
intuitive visualization platform to help maintenance teams make informed
decisions about equipment upkeep and repair scheduling.

## Context and Need

Manufacturing facilities face constant challenges in maintaining
equipment reliability while minimizing maintenance costs. Current
maintenance practices, which often rely on fixed schedules or reactive
approaches, can lead to either unnecessary maintenance or unexpected
breakdowns. Modern sensor technology and data analytics offer an
opportunity to revolutionize this approach through data-driven decision
making.

## Core Challenges

Our project addresses several key challenges in industrial maintenance:

1.  Converting complex sensor readings into meaningful maintenance
    indicators
2.  Building transparent and reliable prediction models for equipment
    health evaluation
3.  Creating an accessible interface for maintenance personnel

## Key Goals

We aim to achieve the following:

1.  Data Analysis and Understanding:
    -   Map relationships across different sensor data
    -   Identify patterns in equipment behavior
    -   Analyze vibration signatures and their implications
2.  Predictive Modeling:
    -   Develop transparent prediction systems
    -   Enable early fault detection
    -   Provide clear reasoning for predictions
3.  User Interface Development:
    -   Enable live monitoring
    -   Present clear status indicators
    -   Facilitate historical analysis

## Project Outputs

Our team will deliver the following key outputs:

-   **Machine Learning Model for Device Ratings:**\
    A robust machine learning model will be developed to analyze sensor
    and operational data, enabling the prediction and generation of
    health ratings for each monitored device. The model will be trained
    and validated using historical and real-time data, with performance
    metrics and retraining guidelines provided.

-   **Interactive Dashboard for Visualization:**\
    An intuitive dashboard will be created to display device health
    ratings and related analytics. The dashboard will support real-time
    monitoring, historical trend analysis, and customizable alerts,
    providing maintenance teams with actionable insights and a
    user-friendly interface for decision-making.

-   **Comprehensive Final Report:**\
    A detailed final report will be prepared for the client, documenting
    the project methodology, data analysis, model development process,
    results, and recommendations. The report will include
    visualizations, key findings, and guidance for future system
    enhancements or scaling.

# Technical Approach

## Data Overview

We have both input and output data from Apr 1 to Apr 15, 2025. The data
consists of 3 devices which is summarized table below.

```{r}
#| label: data-summary-table
#| tbl-cap: "Measurement System Overview"

data_summary <- data.frame(
  Equipment = c("Tube Mill", "Belt Conveyor #8", "High-Temperature Fan #1"),
  Sensor_Points = c("6 locations", "4 locations", "5 locations"),
  Sensor_Data = c("5-second intervals", "5-second intervals", "5-second intervals"),
  Device_Ratings = c("20-minute intervals", "20-minute intervals", "20-minute intervals")
)

kable(data_summary, format = "latex", booktabs = TRUE, longtable = FALSE) %>%
  kable_styling(
    latex_options = c("scale_down", "hold_position"),
    font_size = 9
  )
```

### Input Sensor Data

-   Four key parameters are measured by the sensors at each location.\
-   These sensor readings are collected at 5-second intervals, providing
    high-resolution time series data for each piece of equipment.

```{r}
#| label: input-data-summary
#| tbl-cap: "Input Data Summary"

sensor_info <- data.frame(
  `Sensor Data` = c("Low Frequency Acceleration", 
                    "High Frequency Acceleration", 
                    "Vibration Velocity Z (z-axis)", 
                    "Temperature"),
  `What It Does` = c("Tracks slow vibrations", 
                     "Tracks fast vibrations", 
                     "Tracks vibration strength vertically", 
                     "Monitors component heat levels"),
  `Why It's Important` = c("Detects alignment issues", 
                           "Detect friction issues", 
                           "Detect system damage", 
                           "Helps prevent overheating")
)

kable(sensor_info, format = "latex", booktabs = TRUE, longtable = FALSE) %>%
  kable_styling(
    latex_options = c("scale_down", "hold_position"),
    font_size = 9
  )
```

### Output Device Ratings

-   The system generates 15 device health and status ratings, which
    serve as output parameters for each equipment unit. These include
    metrics such as RMS of Vibration Velocity, Crest Factor, Optimized
    Kurtosis, Rotor Balance Status, and others.
-   Device ratings are produced every 20 minutes, summarizing the
    equipment's condition and performance based on the sensor data.
-   These ratings are generated by a proprietary Matlab program running
    on the machines. The calculation process is a black box: even
    Brilliant Automation does not have access to the internal logic or
    algorithms used to derive these ratings.
-   The ratings are out of 100. As for the definition of the ratings:

1.  Above 80: Healthy
2.  60 to 79: Usable
3.  30 to 59: Warning
4.  Below 30: Fault

```{r}
#| label: device-output-rating-description
#| tbl-cap: "Device Output Rating Descriptions"

device_ratings <- data.frame(
  `Device Rating` = c(
    "alignment_status", "bearing_lubrication", "crest_factor", "electromagnetic_status", 
    "fit_condition", "kurtosis_opt", "rms_10_25khz", "rms_1_10khz", 
    "rotor_balance_status", "rubbing_condition", "velocity_rms", "peak_value_opt"
  ),
  Description = c(
    "Alignment of conveyor components",
    "Lubrication level in bearings",
    "Ratio of peak amplitude to RMS value",
    "Condition of motor's electromagnetic field",
    "Accuracy of component fit",
    "Kurtosis of optimized vibration signal",
    "Root mean square amplitude (10–25 kHz)",
    "Root mean square amplitude (1–10 kHz)",
    "Balance of the rotor",
    "Friction between components",
    "Overall vibration severity",
    "Optimized vibration peak value"
  ),
  `Rating (0–100)` = c(
    "0: Misaligned; 100: Perfectly aligned",
    "0: Dry; 100: Fully lubricated",
    "0: Low peaks; 100: Severe peaks",
    "0: Faulty field; 100: Stable field",
    "0: Poor fit; 100: Perfect fit",
    "0: Low kurtosis; 100: High kurtosis",
    "0: High amplitude; 100: Low amplitude",
    "0: High amplitude; 100: Low amplitude",
    "0: Imbalanced; 100: Perfect balance",
    "0: Severe rubbing; 100: No rubbing",
    "0: High vibrations; 100: Minimal",
    "0: Low peak; 100: Severe peak"
  )
)

kable(device_ratings, format = "latex", booktabs = TRUE, longtable = FALSE) %>%
  kable_styling(
    latex_options = c("scale_down", "hold_position"),
    font_size = 9
  )
```

## Implementation Strategy

The data pipeline starts with sensor data stored in the client's
internal database. An employee accesses this data using a remote desktop
and copies it to their local computer. This step ensures that the
original data is retrieved securely from the client’s internal systems.

Next, the employee uploads the data to Google Drive. A student working
on the project downloads the uploaded files from Google Drive to their
own computer. This method allows for a smooth transfer of data between
the company and the research team.

Once the student receives the data, they preprocess and transform it.
This includes cleaning the data, selecting important variables, and
reformatting it so that it can be used effectively by machine learning
models.

After preprocessing, the sensor data is fed into a machine learning
model. The model is trained to predict various device ratings, such as
alignment status or vibration conditions. These predictions help assess
the current state of the machines.

The model outputs are displayed in a dashboard. This dashboard provides
a clear and interactive way to monitor machine performance over time. It
helps both technical and non-technical users understand the system's
health.

Finally, the data shown on the dashboard is sent into a large language
model (LLM). The LLM analyzes the results and generates insights. These
insights are used to create summary reports for stakeholders, making the
results easier to understand and act on.

![](images/proposal_data_pipeline.png) *Overview of the end-to-end data
pipeline*

## EDA and Data Processing

### Input Features EDA

1.  **Feature Distributions:**

    -   Visualizing the distributions of the input features helps assess
        their spread, skewness, and potential outliers.
    -   This is essential for detecting feature scaling/normalization
        needs or discovering trends related to time dependencies.

    ![](images/input_feat_distributions.png) *Caption: Distribution of
    input features such as `High-Frequency Acceleration`,
    `Low-Frequency Acceleration Z`, `Temperature`, and
    `Vibration Velocity Z`.*

2.  **Boxplots for Sensor Parameters:**

    -   Boxplots show the range, quartiles, and potential outliers of
        input features.
    -   This helps analyze anomalies or extreme measurements in
        parameters such as acceleration and vibration.

    ![](images/input_feat_boxplots.png) *Caption: Boxplots for input
    features reveal the variability and presence of outliers.*

3.  **Feature Correlation Matrix:**

    -   Assessing feature correlations helps identify strongly related
        parameters.
    -   For example, higher vibration and acceleration might indicate
        worn-out components, making these features potential predictors
        of target ratings.

    ![](images/input_feat_corr_mat.png) *Caption: Correlation matrix of
    input features demonstrates the relationships between variables,
    important for feature engineering.*

### Target Features EDA

1.  **Target Rating Distributions:**

    -   Understanding the distributions of target ratings aids in
        identifying their variability and range.
    -   Concentration in specific ranges might indicate clear thresholds
        for equipment health.

    ![](images/target_feat_distributions.png) *Caption: Distribution of
    target features such as `alignment_status`, `bearing_lubrication`,
    and other health metrics.*

2.  **Boxplots for Target Ratings:**

    -   Boxplots for target features provide insights into their
        variability and detect potential inconsistencies (e.g., extreme
        high or low ratings could be indicative of data-quality or
        operational issues).

    ![](images/target_feat_boxplots.png) *Caption: Boxplots for target
    features reveal rating variability and identify notable outliers in
    device health metrics.*

### Data Preprocessing:

We begin by combining the separate date and time columns into a single
timestamp to simplify temporal analysis. The data is then pivoted so
that each sensor measurement and device rating has its own column,
creating a tidy format suitable for machine learning. Because the
ratings are recorded every 20 minutes and sensor data every 5 seconds,
each rating is duplicated across the corresponding 5-second intervals to
align the data. For temperature values, which do not change
significantly within short time spans, we use forward fill to handle
missing values. This preserves data continuity without introducing
significant bias. Sensor location and timestamp are included as features
to capture spatial and temporal context. Lastly, the device column is
dropped since we train a separate model for each device, making that
column redundant.

## Model Development

The model aims to predict device ratings for each equipment unit, using
sensor data as input. Our modeling strategy progresses from simple to
complex.

```{r}
#| label: model-comparison
#| tbl-cap: "Model Comparison Overview"
#| results: asis

model_comparison <- data.frame(
  Model = c("Baseline", "Ridge", "PolyRidge (deg 2)", "PolyRidge (deg 5)", 
            "Random Forest", "Neural Network"),
  Complexity = c("Very Low", "Low", "Medium", "High", "Medium–High", "High"),
  Interpretability = c("Perfectly clear", "High", "Medium", "Low", "Low–Medium", "Low"),
  Flexibility = c("None", "Only linear fits", "Simple non-linearities", 
                  "Highly flexible curves", "Arbitrary non-linear", "Very high"),
  Overfit_Risk = c("None", "Low–Medium", "Medium", "High", "Medium", "High"),
  Compute_Cost = c("Minimal", "Fast", "Moderate", "Heavy", "Moderate–High", "Heavy")
)

kable(model_comparison, format = "latex", booktabs = TRUE, longtable = FALSE) %>%
  kable_styling(
    latex_options = c("scale_down", "hold_position"),
    font_size = 9
  )
```


## Interactive Dashboard

The interactive dashboard serves as the central interface for
maintenance teams and stakeholders to monitor machine health and
understand sensor behavior in real time. It combines predictive model
outputs and raw sensor readings in a clear, user-friendly layout. At the
top of the dashboard, dropdown filters allow users to select a specific
device and sensor, enabling targeted exploration. The radar charts
visualize device health ratings across multiple metrics, helping teams
quickly assess overall performance. Below and to the right, time-series
and frequency plots show raw sensor data to help identify patterns,
anomalies, or failure signals. This layered design allows users to
connect machine learning predictions with actual sensor behavior.

The dashboard is built to meet industrial standards, as defined by
client specifications. Its layout and visualization types are aligned
with existing operational workflows, making it easy for technicians and
analysts to interpret results. The responsiveness and modularity of the
dashboard ensure it remains scalable for additional sensors or machines
in the future.

# Project Timeline

```{r}
#| label: project-timeline
#| tbl-cap: "Project Timeline and Outputs"

library(knitr)
library(kableExtra)

timeline <- data.frame(
  Week = 1:8,
  Stage = c("Project launch, data processing", 
            "Data product MVPs", 
            "Full data test", 
            "Model revision", 
            "Model revision", 
            "Output refinement", 
            "Output refinement", 
            "Final checks"),
  Outputs = c("Wrangled dataset, toy dataset, MDS Proposal presentation",
              "MVP dashboard, MVP models, MDS Proposal report",
              "Cloud computing pipeline, initial results",
              "Engineered features",
              "Engineered features",
              "Final dashboard, final models, MDS draft data product",
              "Final dashboard, final models, MDS presentation",
              "Final report, MDS final data product")
)

kable(timeline, format = "latex", booktabs = TRUE, longtable = FALSE) %>%
  kable_styling(
    latex_options = c("scale_down", "hold_position"),
    font_size = 9
  )
```
